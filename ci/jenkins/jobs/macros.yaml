- builder:
    name: builder-job-updater
    builders:
      - shell: |-
          cp /var/lib/jenkins/utils/defaults.yaml ci/jenkins/jobs
          jenkins-jobs update -r ci/jenkins/jobs
          rm ci/jenkins/jobs/defaults.yaml

- builder:
    name: builder-workload-cluster-setup
    builders:
      - shell: |-
          #!/bin/bash

          saveLogs() {
            echo "=== Truncate old logs ==="
            export LOG_DIR=/var/lib/jenkins/antrea_logs
            find ${LOG_DIR}/* -type d -mmin +10080 | xargs -r rm -rf

            CLUSTER_LOG_DIR="${LOG_DIR}/${cluster}"
            echo "=== Saving capi logs ==="
            mkdir -p ${CLUSTER_LOG_DIR}/capi
            kubectl get -n capi-system pods -o name | awk '{print $1}' | while read capi_pod; do
              capi_pod_name=$(echo ${capi_pod} | cut -d'/' -f 2)
              kubectl logs ${capi_pod_name} -n capi-system --tail=400 > ${CLUSTER_LOG_DIR}/capi/${capi_pod_name}
            done

            echo "=== Saving capv logs ==="
            mkdir -p ${CLUSTER_LOG_DIR}/capv
            kubectl get -n capv-system pods -o name | awk '{print $1}' | while read capv_pod; do
              capv_pod_name=$(echo ${capv_pod} | cut -d'/' -f 2)
              kubectl logs ${capv_pod_name} -n capv-system --tail=400 > ${CLUSTER_LOG_DIR}/capv/${capv_pod_name}
            done
          }

          set -e
          cluster="${JOB_NAME}-${BUILD_NUMBER}"

          WORK_HOME="/var/lib/jenkins"
          export KUBECONFIG="${WORK_HOME}/.kube/config"
          rm -rf jenkins || true

          echo '=== Generate key pair ==='
          mkdir -p ${WORKSPACE}/jenkins/key
          ssh-keygen -b 2048 -t rsa -f  "${WORKSPACE}/jenkins/key/antrea-ci-key" -q -N ""
          publickey="$(cat ${WORKSPACE}/jenkins/key/antrea-ci-key.pub)"

          echo "=== namespace value substitution ==="
          mkdir -p ${WORKSPACE}/jenkins/out
          cp ci/cluster-api/vsphere/templates/* ${WORKSPACE}/jenkins/out
          sed -i "s/CLUSTERNAMESPACE/${cluster}/g" "${WORKSPACE}/jenkins/out/cluster.yaml"
          sed -i "s/CLUSTERNAME/${cluster}/g" "${WORKSPACE}/jenkins/out/cluster.yaml"
          sed -i "s|SSHAUTHORIZEDKEYS|${publickey}|g" "${WORKSPACE}/jenkins/out/cluster.yaml"
          sed -i "s/CLUSTERNAMESPACE/${cluster}/g" "${WORKSPACE}/jenkins/out/namespace.yaml"

          echo "=== network spec value substitution==="
          cluster_defaults="${WORK_HOME}/utils/CLUSTERDEFAULTS"
          while IFS= read -r line
          do
            IFS='=' read -ra kv <<< "$line"
            sed -i "s|${kv[0]}|${kv[1]}|g" "${WORKSPACE}/jenkins/out/cluster.yaml"
          done < "$cluster_defaults"

          echo '=== Create a cluster in management cluster ==='
          kubectl apply -f "${WORKSPACE}/jenkins/out/namespace.yaml"
          kubectl apply -f "${WORKSPACE}/jenkins/out/cluster.yaml"

          echo '=== Wait for workload cluster secret for 10 min ==='
          for t in {1..10}
          do
            sleep 1m
            echo '=== Get kubeconfig (try for 1m) ==='
            if kubectl get secret/${cluster}-kubeconfig -n${cluster} ; then
              kubectl get secret/${cluster}-kubeconfig -n${cluster} -o json \
                | jq -r .data.value \
                | base64 --decode \
                > "${WORKSPACE}/jenkins/out/kubeconfig"
              touch jenkins/SECRET_EXIST
              break
            fi
          done

          if !(test -f jenkins/SECRET_EXIST); then
            echo "=== Failed to get secret ==="
            savelogs
            exit 1
          else
            export KUBECONFIG="${WORKSPACE}/jenkins/out/kubeconfig"
            echo "=== Waiting all nodes up for 10 min ==="

            set +e
            for t in {1..10}
            do
              sleep 1m
              echo "=== Get node (try for 1m) ==="
              mdNum="$(kubectl get node | grep -c ${cluster}-md)"
              if [ "${mdNum}" == "2" ]; then
                echo "=== Setup workload cluster succeeded ==="
                exit 0
              fi
            done
            set -e

            echo "=== Failed to make all nodes up ==="
            savelogs
            exit 1
          fi

- builder:
    name: builder-workload-cluster-cleanup
    builders:
      - shell: |-
          #!/bin/bash
          set -ex
          echo '=== Clean up workload cluster ==='
          export KUBECONFIG="/var/lib/jenkins/.kube/config"

          cluster="${JOB_NAME}-${BUILD_NUMBER}"
          kubectl delete ns ${cluster}
          rm -rf "${WORKSPACE}/jenkins"

          echo "=== Cleanup workload cluster ${cluster} succeeded ==="

          if !(test -f TEST_FAILURE); then
            echo "=== SUCCESS !!! ==="
            exit 0
          fi
          echo "=== FAILURE !!! ==="
          exit 1

- builder:
    name: builder-eks-cluster-cleanup
    builders:
      - shell: |-
          #!/bin/bash
          set -ex
          source /home/ubuntu/.bashrc
          ./ci/test-conformance-eks.sh --cluster-name "${CLUSTERNAME}" --cleanup-only

- builder:
    name: builder-gke-cluster-cleanup
    builders:
      - shell: |-
         #!/bin/bash
         set -ex
         source /home/ubuntu/.bashrc
         ./ci/test-conformance-gke.sh --cluster-name "${CLUSTERNAME}" --cleanup-only

- builder:
    name: builder-workload-cluster-gc
    builders:
      - shell: |-
          #!/bin/bash
          set -ex
          echo "=== Auto cleanup starts ==="
          export KUBECONFIG="/var/lib/jenkins/.kube/config"

          kubectl get namespace -l antrea-ci | awk '$3 ~ "[0-9][hd]" || $3 ~ "[6-9][0-9]m"  && $2 ~ "Active" {print $1}' | while read cluster; do
            echo "=== Currently ${cluster} has been live for more than 1h ==="
            kubectl delete ns ${cluster}
            echo "=== Old namespace ${cluster} is deleted !!! ==="
          done

          echo "=== Auto cleanup finished ==="

- builder:
    name: builder-list-tests
    builders:
      - shell: |-
          set +x

          rm -f COMMENT_EXIST
          rm -f body.json
          echo "{{\"body\": \"Thanks for your PR.\\\nUnit tests and code linters are run automatically every time the PR is updated.\\\nE2e, conformance and network policy tests can only be triggered by a member of the vmware-tanzu organization. Regular contributors to the project should join the org.\\\n\\\nThe following commands are available:\\\n* \`/test-e2e\`: to trigger e2e tests.\\\n* \`/skip-e2e\`: to skip e2e tests.\\\n* \`/test-conformance\`: to trigger conformance tests.\\\n* \`/skip-conformance\`: to skip conformance tests.\\\n* \`/test-whole-conformance\`: to trigger all conformance tests on linux.\\\n* \`/test-networkpolicy\`: to trigger networkpolicy tests.\\\n* \`/skip-networkpolicy\`: to skip networkpolicy tests.\\\n* \`/test-windows-conformance\`: to trigger windows conformance tests.\\\n* \`/skip-windows-conformance\`: to skip windows conformance tests.\\\n* \`/test-all\`: to trigger all tests.\\\n* \`/skip-all\`: to skip all tests.\\\n\\\nThese commands can only be run by members of the vmware-tanzu organization.\"}}" > body.json

          B="$(cat body.json | jq .body)"

          # read -r: preserve \n from the input line.
          curl "https://api.github.com/repos/{org_repo}/issues/${{ghprbPullId}}/comments" | jq '.[].body' | while read -r LINE
          do
            if [ "$LINE" = "$B" ]
            then
              echo Found existing comment!
              # pipeline runs in subshell, setting variable won't have effect on the parent process
              # so use a file as a flag
              touch COMMENT_EXIST
              break
            fi
          done

          if !(test -f COMMENT_EXIST)
          then
            echo Ask the question!
            curl -u "${{GH_CREDENTIAL}}" -X POST -H 'Content-type: application/json' -d @body.json "https://api.github.com/repos/{org_repo}/issues/${{ghprbPullId}}/comments"
          else
            echo Question already asked!
          fi

- builder:
    name: builder-job-validator
    builders:
      - shell: |-
          cp /var/lib/jenkins/utils/defaults.yaml ci/jenkins/jobs
          jenkins-jobs test -r ci/jenkins/jobs/
          rm ci/jenkins/jobs/defaults.yaml

- builder:
    name: builder-pending-label
    builders:
      - shell: 'exit 1 # fail on purpose'

- builder:
    name: builder-prepare-antrea
    builders:
      - shell: |-
          echo ====== Building Antrea for the Following Commit ======

          git show --numstat

          export GO111MODULE=on
          export GOPATH=/var/lib/jenkins/go
          export GOROOT=/usr/local/go
          export GOCACHE="${WORKSPACE}/../gocache"
          export PATH=$GOROOT/bin:$PATH

          make clean
          docker pull antrea/openvswitch --all-tags
          docker images | grep "${JOB_NAME}" | awk '{print $3}' | xargs -r docker rmi -f || true
          # Clean up dangling images generated in previous builds. Recent ones must be excluded
          # because they might be being used in other builds running simultaneously.
          docker image prune -f --filter "until=1h" || true
          VERSION="$JOB_NAME-$BUILD_NUMBER" make

          sed -i "s|#serviceCIDR: 10.96.0.0/12|serviceCIDR: 100.64.0.0/13|g" build/yamls/antrea.yml
          sed -i 's|#enablePrometheusMetrics: false|enablePrometheusMetrics: true|g' build/yamls/antrea.yml
      - shell: |-
          echo ====== Delivering Antrea to all the Nodes ======
          export KUBECONFIG="${WORKSPACE}/jenkins/out/kubeconfig"
          DOCKER_IMG_VERSION="$JOB_NAME-$BUILD_NUMBER"

          docker save -o antrea-ubuntu.tar antrea/antrea-ubuntu:${DOCKER_IMG_VERSION}

          kubectl get nodes -o wide --no-headers=true | awk '$3 == "master" {print $6}' | while read master_ip; do
            scp -o StrictHostKeyChecking=no -i jenkins/key/antrea-ci-key build/yamls/*.yml capv@${master_ip}:~
          done

          kubectl get nodes -o wide --no-headers=true | awk '{print $6}' | while read IP; do
            rsync -avr --progress --inplace -e "ssh -o StrictHostKeyChecking=no -i jenkins/key/antrea-ci-key" antrea-ubuntu.tar capv@${IP}:/home/capv/antrea-ubuntu.tar
            ssh -o StrictHostKeyChecking=no -i jenkins/key/antrea-ci-key -n capv@${IP} "sudo crictl images | grep 'antrea-ubuntu' | awk '{print \$3}' | xargs -r crictl rmi ; sudo ctr -n=k8s.io images import /home/capv/antrea-ubuntu.tar ; sudo ctr -n=k8s.io images tag docker.io/antrea/antrea-ubuntu:${DOCKER_IMG_VERSION} docker.io/antrea/antrea-ubuntu:latest ; sudo crictl images | grep '<none>' | awk '{print \$3}' | xargs -r crictl rmi" || true
          done

- builder:
    name: builder-e2e
    builders:
      - shell: |-
          #!/bin/bash
          set -ex
          echo ====== Running Antrea E2E Tests ======

          export GO111MODULE=on
          export WORK_HOME=/var/lib/jenkins
          export GOPATH=$WORK_HOME/go
          export GOROOT=/usr/local/go
          export GOCACHE=$WORK_HOME/.cache/go-build
          export PATH=$GOROOT/bin:$PATH
          export KUBECONFIG=${WORKSPACE}/jenkins/out/kubeconfig
          cluster="${JOB_NAME}-${BUILD_NUMBER}"

          mkdir -p test/e2e/infra/vagrant/playbook/kube
          cp -f "${WORKSPACE}/jenkins/out/kubeconfig" test/e2e/infra/vagrant/playbook/kube/config

          echo "=== Generate ssh-config ==="
          cp -f ci/jenkins/ssh-config test/e2e/infra/vagrant/ssh-config
          master_name="$(kubectl get nodes -o wide --no-headers=true | awk '$3 == "master" {print $1}')"
          master_ip="""$(kubectl get nodes -o wide --no-headers=true | awk '$3 == "master" {print $6}')"
          echo "=== Master node ip: ${master_ip} ==="
          sed -i "s/MASTERNODEIP/${master_ip}/g" test/e2e/infra/vagrant/ssh-config
          echo "=== Move kubeconfig to master ==="
          ssh -o StrictHostKeyChecking=no -i jenkins/key/antrea-ci-key -n capv@${master_ip} "mkdir .kube"
          scp -o StrictHostKeyChecking=no -i jenkins/key/antrea-ci-key jenkins/out/kubeconfig capv@${master_ip}:~/.kube/config
          sed -i "s/CONTROLPLANENODE/${master_name}/g" test/e2e/infra/vagrant/ssh-config
          echo "    IdentityFile ${WORKSPACE}/jenkins/key/antrea-ci-key" >> test/e2e/infra/vagrant/ssh-config

          # Run and configure Prometheus
          kubectl apply -f build/yamls/antrea-prometheus.yml

          set +e
          mkdir -p `pwd`/antrea-test-logs
          go test -v -timeout=20m github.com/vmware-tanzu/antrea/test/e2e --logs-export-dir `pwd`/antrea-test-logs --prometheus

          test_rc=$?
          set -e

          tar -zcf antrea-test-logs.tar.gz antrea-test-logs

          echo ====== Cleanup Antrea Installation ======

          for antrea_yml in build/yamls/*.yml
          do
            kubectl delete -f ${antrea_yml} --ignore-not-found=true || true
          done

          kubectl delete ns antrea-test || true

          if [ "$test_rc" == "1" ]
          then
            echo "=== TEST FAILURE !!! ==="
            touch TEST_FAILURE
          fi
          echo "=== TEST SUCCESS !!! ==="

- builder:
    name: builder-conformance
    builders:
      - shell: |-
          #!/bin/bash
          set -ex
          echo ====== Running Antrea Conformance Tests ======

          export GO111MODULE=on
          export WORK_HOME=/var/lib/jenkins
          export GOPATH=$WORK_HOME/go
          export GOROOT=/usr/local/go
          export GOCACHE=$WORK_HOME/.cache/go-build
          export PATH=$GOROOT/bin:$PATH
          export KUBECONFIG=$WORKSPACE/jenkins/out/kubeconfig

          kubectl apply -f build/yamls/antrea.yml
          kubectl rollout restart deployment/coredns -n kube-system
          kubectl rollout status --timeout=5m deployment/coredns -n kube-system
          kubectl rollout status --timeout=5m deployment.apps/antrea-controller -n kube-system
          kubectl rollout status --timeout=5m daemonset/antrea-agent -n kube-system

          kubectl get nodes -o wide --no-headers=true | awk '$3 == "master" {{print $6}}' | while read master_ip; do
            echo "=== Move kubeconfig to master ==="
            ssh -o StrictHostKeyChecking=no -i jenkins/key/antrea-ci-key -n capv@${{master_ip}} "mkdir .kube"
            scp -o StrictHostKeyChecking=no -i jenkins/key/antrea-ci-key jenkins/out/kubeconfig capv@${{master_ip}}:~/.kube/config

            conformance_image_version=$(head -n1 ci/k8s-conformance-image-version)
            echo  "=== Run sonobuoy with conformance image version ${{conformance_image_version}} ==="

            sonobuoy delete --wait --kubeconfig jenkins/out/kubeconfig
            if [ '{mode_regex}' == "" ]; then
              sonobuoy run --wait --timeout 1800 --e2e-focus '{focus_regex}' --e2e-skip '{skip_regex}' --e2e-parallel y --kube-conformance-image-version ${{conformance_image_version}} --kubeconfig jenkins/out/kubeconfig
            else
              sonobuoy run --wait --timeout 7200 --mode='{mode_regex}' --e2e-parallel y --kube-conformance-image-version ${{conformance_image_version}} --kubeconfig jenkins/out/kubeconfig
            fi
            sonobuoy retrieve --kubeconfig jenkins/out/kubeconfig
            echo '=== Print all results ==='
            sonobuoy results *sonobuoy*.tar.gz
            echo '=== Print failed cases if any ==='
            sonobuoy results *sonobuoy*.tar.gz >> RESULT

            if grep -Fxq "Failed tests:" RESULT
            then
              echo "Failed cases exist."
              touch TEST_FAILURE
            else
              echo "All tests passed."
            fi

            echo "=== Clean up sonobouy resources ==="
            sonobuoy delete --wait --kubeconfig jenkins/out/kubeconfig
            rm RESULT
          done

          echo ====== Cleanup Antrea Installation ======

          for antrea_yml in /var/lib/jenkins/*.yml
          do
            kubectl delete -f ${{antrea_yml}} --ignore-not-found=true || true
          done

          kubectl delete ns antrea-test || true
