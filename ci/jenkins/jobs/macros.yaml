- builder:
    name: builder-job-updater
    builders:
      - shell: |-
          cp /var/lib/jenkins/utils/defaults.yaml ci/jenkins/jobs
          jenkins-jobs update -r ci/jenkins/jobs
          rm ci/jenkins/jobs/defaults.yaml

- builder:
    name: builder-workload-cluster-setup
    builders:
      - shell: |-
          #!/bin/bash
          cluster="${JOB_NAME}-${BUILD_NUMBER}"
          newNS="${cluster}"
          echo "=== This cluster is: ${cluster} ==="
          echo "=== This namespace is: ${newNS} ==="
          echo "CLUSTERNAME=${cluster}" >> ci_properties.txt

          WORK_HOME="/var/lib/jenkins"
          export KUBECONFIG="${WORK_HOME}/kubeconfig-mgmt"

          echo '=== Generate key pair ==='
          mkdir -p ${WORKSPACE}/jenkins/key
          ssh-keygen -b 2048 -t rsa -f  "${WORKSPACE}/jenkins/key/antrea-ci-key" -q -N ""
          publickey="$(cat ${WORKSPACE}/jenkins/key/antrea-ci-key.pub)"

          echo "=== namespace value substitution ==="
          mkdir -p ${WORKSPACE}/jenkins/out
          cp ci/cluster-api/vsphere/templates/* ${WORKSPACE}/jenkins/out
          manifests=("cluster" "controlplane" "machinedeployment")
          for f in "${manifests[@]}"
          do
            sed -i "s/CLUSTERNAMESPACE/${newNS}/g" "${WORKSPACE}/jenkins/out/${f}.yaml"
            sed -i "s/CLUSTERNAME/${cluster}/g" "${WORKSPACE}/jenkins/out/${f}.yaml"
            sed -i "s|SSHAUTHORIZEDKEYS|${publickey}|g" "${WORKSPACE}/jenkins/out/${f}.yaml"
          done
          sed -i "s/NAMESPACENAME/${newNS}/g" "${WORKSPACE}/jenkins/out/namespace.yaml"

          echo "=== network spec value substitution==="
          cluster_defaults="${WORK_HOME}/utils/CLUSTERDEFAULTS"
          while IFS= read -r line
          do
            IFS='=' read -ra kv <<< "$line"
            for f in "${manifests[@]}"
            do
              sed -i "s|${kv[0]}|${kv[1]}|g" "${WORKSPACE}/jenkins/out/${f}.yaml"
            done
          done < "$cluster_defaults"

          echo '=== Create a cluster in management cluster ==='
          kubectl apply -f "${WORKSPACE}/jenkins/out/namespace.yaml"
          kubectl apply -f "${WORKSPACE}/jenkins/out/cluster.yaml"
          kubectl apply -f "${WORKSPACE}/jenkins/out/controlplane.yaml"
          kubectl apply -f "${WORKSPACE}/jenkins/out/machinedeployment.yaml"

          echo '=== Try to get secret for 10 min ==='
          for t in {1..10}
          do
            sleep 1m
            echo '=== Get kubeconfig (try for 1m) ==='
            if kubectl get secret ${cluster}-kubeconfig -n${newNS} ; then
              kubectl get secret ${cluster}-kubeconfig -n${newNS} -o=jsonpath='{.data.value}' | \
                { base64 -d 2>/dev/null ; } >"${WORKSPACE}/jenkins/out/kubeconfig"
              touch jenkins/SECRET_EXIST
              break
            fi
          done

          if !(test -f jenkins/SECRET_EXIST); then
            echo "=== Fail to get secret ==="
            
            echo "=== Remove too many logs ==="
            export LOG_DIR=/var/lib/jenkins/antrea_logs
            find ${LOG_DIR}/* -type d -mmin +10080 | xargs rm -rf

            CLUSTER_LOG_DIR="${LOG_DIR}/${cluster}"
            echo "=== Saving capi logs ==="
            mkdir -p ${CLUSTER_LOG_DIR}/capi
            kubectl get -n capi-system pods -o name | awk '{print $1}' | while read capi_pod; do
              capi_pod_name=$(echo ${capi_pod} | cut -d'/' -f 2)
              kubectl logs ${capi_pod_name} -n capi-system --tail=100 > ${CLUSTER_LOG_DIR}/capi/${capi_pod_name}
            done

            echo "=== Saving capv logs ==="
            mkdir -p ${CLUSTER_LOG_DIR}/capv
            kubectl get -n capv-system pods -o name | awk '{print $1}' | while read capv_pod; do
              capv_pod_name=$(echo ${capv_pod} | cut -d'/' -f 2)
              kubectl logs ${capv_pod_name} -n capv-system --tail=100 > ${CLUSTER_LOG_DIR}/capv/${capv_pod_name}
            done
            
            exit 1
          else
            echo "=== Setup cluster succeeded ==="
          fi

- builder:
    name: builder-workload-cluster-cleanup
    builders:
      - shell: |-
          #!/bin/bash
          cluster="${CLUSTERNAME}"

          echo '=== Clean up cluster ==='
          export KUBECONFIG="/var/lib/jenkins/kubeconfig-mgmt"

          kubectl delete --ignore-not-found=true Machine ${cluster}-controlplane-0 -n ${cluster}
          kubectl delete --ignore-not-found=true MachineDeployment ${cluster}-md-0 -n ${cluster}

          retry=12
          while [ "${retry}" -gt 0 ]; do
            echo '=== Waiting for Machines to be deleted ==='
            machines="$(kubectl get machine -n ${cluster} --no-headers=true 2>/dev/null | wc -l)"
            if [ "${machines}" -eq 0 ]; then
              break
            fi
            echo '=== Remaining Machines ==='
            kubectl get machine -n ${cluster}
            sleep 10
            retry=$((retry-1))
          done
          if [ "${retry}" -eq 0 ]; then
            echo "=== Failed to delete machines! ==="
            exit 1
          fi

          kubectl delete --ignore-not-found=true VSphereCluster ${cluster} -n ${cluster}
          kubectl delete --ignore-not-found=true Cluster ${cluster} -n ${cluster}
          kubectl delete --ignore-not-found=true ns ${cluster}

          rm -rf "${WORKSPACE}/jenkins"
          echo "=== Cleanup cluster ${cluster} succeeded ==="

- builder:
    name: builder-workload-cluster-gc
    builders:
      - shell: |-
          #!/bin/bash
          echo "=== Auto cleanup starts ==="
          export KUBECONFIG="/var/lib/jenkins/kubeconfig-mgmt"

          kubectl get namespace -l antrea-ci | awk '$3 ~ "[0-9][hd]" && $2 ~ "Active" {print $1}' | while read cluster_name; do
            echo "=== Currently ${cluster_name} has been live for more than 1h ==="
            kubectl delete --ignore-not-found=true Machine ${cluster_name}-controlplane-0 -n ${cluster_name}
            kubectl delete --ignore-not-found=true MachineDeployment ${cluster_name}-md-0 -n ${cluster_name}

            retry=12
            while [ "${retry}" -gt 0 ]; do
              echo '=== Waiting for Machines to be deleted ==='
              machines="$(kubectl get machine -n ${cluster_name} --no-headers=true 2>/dev/null | wc -l)"
              if [ "${machines}" -eq 0 ]; then
                break
              fi
              echo '=== Remaining Machines ==='
              kubectl get machine -n ${cluster_name}
              sleep 10
              retry=$((retry-1))
            done
            if [ "${retry}" -eq 0 ]; then
              echo "=== Failed to delete machines! ==="
              continue
            fi

            kubectl delete --ignore-not-found=true VSphereCluster ${cluster_name} -n ${cluster_name}
            kubectl delete --ignore-not-found=true Cluster ${cluster_name} -n ${cluster_name}
            kubectl delete --ignore-not-found=true ns ${cluster_name}
            echo "=== Old namespace ${cluster_name} is deleted !!! ==="
          done

          echo "=== Auto cleanup finished ==="

- builder:
    name: builder-list-tests
    builders:
      - shell: |-
          set +x

          rm -f COMMENT_EXIST
          rm -f body.json
          echo "{{\"body\": \"Thanks for your PR.\\\nUnit tests and code linters are run automatically every time the PR is updated.\\\nE2e, conformance and network policy tests can only be triggered by a member of the vmware-tanzu organization. Regular contributors to the project should join the org.\\\n\\\nThe following commands are available:\\\n* \`/test-e2e\`: to trigger e2e tests.\\\n* \`/skip-e2e\`: to skip e2e tests.\\\n* \`/test-conformance\`: to trigger conformance tests.\\\n* \`/skip-conformance\`: to skip conformance tests.\\\n* \`/test-networkpolicy\`: to trigger networkpolicy tests.\\\n* \`/skip-networkpolicy\`: to skip networkpolicy tests.\\\n* \`/test-all\`: to trigger all tests.\\\n* \`/skip-all\`: to skip all tests.\\\n\\\nThese commands can only be run by members of the vmware-tanzu organization.\"}}" > body.json

          B="$(cat body.json | jq .body)"

          # read -r: preserve \n from the input line.
          curl "https://api.github.com/repos/{org_repo}/issues/${{ghprbPullId}}/comments" | jq '.[].body' | while read -r LINE
          do
            if [ "$LINE" = "$B" ]
            then
              echo Found existing comment!
              # pipeline runs in subshell, setting variable won't have effect on the parent process
              # so use a file as a flag
              touch COMMENT_EXIST
              break
            fi
          done

          if !(test -f COMMENT_EXIST)
          then
            echo Ask the question!
            curl -u "${{GH_CREDENTIAL}}" -X POST -H 'Content-type: application/json' -d @body.json "https://api.github.com/repos/{org_repo}/issues/${{ghprbPullId}}/comments"
          else
            echo Question already asked!
          fi

- builder:
    name: builder-job-validator
    builders:
      - shell: |-
          cp /var/lib/jenkins/utils/defaults.yaml ci/jenkins/jobs
          jenkins-jobs test -r ci/jenkins/jobs/
          rm ci/jenkins/jobs/defaults.yaml

- builder:
    name: builder-pending-label
    builders:
      - shell: 'exit 1 # fail on purpose'

- builder:
    name: builder-prepare-antrea
    builders:
      - shell: |-
          echo ====== Building Antrea for the Following Commit ======

          git show --numstat

          export GO111MODULE=on
          export GOPATH=/var/lib/jenkins/go
          export GOROOT=/usr/local/go
          export GOCACHE="${WORKSPACE}/../gocache"
          export PATH=$GOROOT/bin:$PATH

          make clean
          docker pull antrea/openvswitch --all-tags
          docker images | grep "${JOB_NAME}" | awk '{print $3}' | xargs -r docker rmi -f || true
          # Clean up dangling images generated in previous builds. Recent ones must be excluded
          # because they might be being used in other builds running simultaneously.
          docker image prune -f --filter "until=1h" || true
          VERSION="$JOB_NAME-$BUILD_NUMBER" make

          sed -i "s|#serviceCIDR: 10.96.0.0/12|serviceCIDR: 100.64.0.0/13|g" build/yamls/antrea.yml
      - shell: |-
          echo ====== Delivering Antrea to all the Nodes ======
          export KUBECONFIG="${WORKSPACE}/jenkins/out/kubeconfig"
          DOCKER_IMG_VERSION="$JOB_NAME-$BUILD_NUMBER"

          docker save -o antrea-ubuntu.tar antrea/antrea-ubuntu:${DOCKER_IMG_VERSION}

          kubectl get nodes -o wide --no-headers=true | awk '$3 == "master" {print $6}' | while read master_ip; do
            scp -o StrictHostKeyChecking=no -i jenkins/key/antrea-ci-key build/yamls/*.yml capv@${master_ip}:~
          done

          kubectl get nodes -o wide --no-headers=true | awk '{print $6}' | while read IP; do
            rsync -avr --progress --inplace -e "ssh -o StrictHostKeyChecking=no -i jenkins/key/antrea-ci-key" antrea-ubuntu.tar capv@${IP}:/home/capv/antrea-ubuntu.tar
            ssh -o StrictHostKeyChecking=no -i jenkins/key/antrea-ci-key -n capv@${IP} "sudo crictl images | grep 'antrea-ubuntu' | awk '{print \$3}' | xargs -r crictl rmi ; sudo ctr -n=k8s.io images import /home/capv/antrea-ubuntu.tar ; sudo ctr -n=k8s.io images tag docker.io/antrea/antrea-ubuntu:${DOCKER_IMG_VERSION} docker.io/antrea/antrea-ubuntu:latest ; sudo crictl images | grep '<none>' | awk '{print \$3}' | xargs -r crictl rmi" || true
          done

- builder:
    name: builder-e2e
    builders:
      - shell: |-
          #!/bin/bash
          echo ====== Running Antrea E2E Tests ======

          export GO111MODULE=on
          export WORK_HOME=/var/lib/jenkins
          export GOPATH=$WORK_HOME/go
          export GOROOT=/usr/local/go
          export GOCACHE=$WORK_HOME/.cache/go-build
          export PATH=$GOROOT/bin:$PATH
          export KUBECONFIG=${WORKSPACE}/jenkins/out/kubeconfig
          cluster="${JOB_NAME}-${BUILD_NUMBER}"

          mkdir -p test/e2e/infra/vagrant/playbook/kube
          cp -f "${WORKSPACE}/jenkins/out/kubeconfig" test/e2e/infra/vagrant/playbook/kube/config

          echo "=== Generate ssh-config ==="
          cp -f ci/jenkins/ssh-config test/e2e/infra/vagrant/ssh-config
          kubectl get nodes -o wide --no-headers=true | awk '$3 == "master" {print $6}' | while read master_ip; do
            echo "=== Master node ip: ${master_ip} ==="
            sed -i "s/MASTERNODEIP/${master_ip}/g" test/e2e/infra/vagrant/ssh-config

            echo "=== Move kubeconfig to master ==="
            ssh -o StrictHostKeyChecking=no -i jenkins/key/antrea-ci-key -n capv@${master_ip} "mkdir .kube"
            scp -o StrictHostKeyChecking=no -i jenkins/key/antrea-ci-key jenkins/out/kubeconfig capv@${master_ip}:~/.kube/config
          done
          sed -i "s/CONTROLPLANENODE/${cluster}-controlplane-0/g" test/e2e/infra/vagrant/ssh-config
          echo "    IdentityFile ${WORKSPACE}/jenkins/key/antrea-ci-key" >> test/e2e/infra/vagrant/ssh-config

          set +e
          mkdir -p `pwd`/antrea-test-logs
          go test -v github.com/vmware-tanzu/antrea/test/e2e --logs-export-dir `pwd`/antrea-test-logs -timeout=20m

          test_rc=$?
          set -e

          tar -zcf antrea-test-logs.tar.gz antrea-test-logs

          echo ====== Cleanup Antrea Installation ======

          for antrea_yml in build/yamls/*.yml
          do
            kubectl delete -f ${antrea_yml} --ignore-not-found=true || true
          done

          kubectl delete ns antrea-test || true

          if [ "$test_rc" == "1" ]
          then
            echo "=== TEST FAILURE !!! ==="
            exit 1
          fi
          echo "=== TEST SUCCESS !!! ==="
          exit 0

- builder:
    name: builder-conformance
    builders:
      - shell: |-
          #!/bin/bash
          echo ====== Running Antrea Conformance Tests ======

          export GO111MODULE=on
          export WORK_HOME=/var/lib/jenkins
          export GOPATH=$WORK_HOME/go
          export GOROOT=/usr/local/go
          export GOCACHE=$WORK_HOME/.cache/go-build
          export PATH=$GOROOT/bin:$PATH
          export KUBECONFIG=$WORKSPACE/jenkins/out/kubeconfig

          kubectl apply -f build/yamls/antrea.yml
          kubectl rollout restart deployment/coredns -n kube-system
          kubectl rollout status --timeout=5m deployment/coredns -n kube-system
          kubectl rollout status --timeout=5m deployment.apps/antrea-controller -n kube-system
          kubectl rollout status --timeout=5m daemonset/antrea-agent -n kube-system

          kubectl get nodes -o wide --no-headers=true | awk '$3 == "master" {{print $6}}' | while read master_ip; do
            echo "=== Move kubeconfig to master ==="
            ssh -o StrictHostKeyChecking=no -i jenkins/key/antrea-ci-key -n capv@${{master_ip}} "mkdir .kube"
            scp -o StrictHostKeyChecking=no -i jenkins/key/antrea-ci-key jenkins/out/kubeconfig capv@${{master_ip}}:~/.kube/config

            conformance_image_version=$(head -n1 ci/k8s-conformance-image-version)
            echo  "=== Run sonobuoy with conformance image version ${{conformance_image_version}} ==="

            sonobuoy delete --wait --kubeconfig jenkins/out/kubeconfig
            sonobuoy run --wait --e2e-focus '{focus_regex}' --e2e-skip '{skip_regex}' --e2e-parallel y --kube-conformance-image-version ${{conformance_image_version}} --kubeconfig jenkins/out/kubeconfig
            sonobuoy retrieve --kubeconfig jenkins/out/kubeconfig
            echo '=== Print all results ==='
            sonobuoy results *sonobuoy*.tar.gz
            echo '=== Print failed cases if any ==='
            sonobuoy results *sonobuoy*.tar.gz >> RESULT

            if grep -Fxq "Failed tests:" RESULT
            then
              echo "Failed cases exist."
              touch TEST_FAILURE
            else
              echo "All tests passed."
            fi

            echo "=== Clean up sonobouy resources ==="
            sonobuoy delete --wait --kubeconfig jenkins/out/kubeconfig
            rm RESULT
          done

          echo ====== Cleanup Antrea Installation ======

          for antrea_yml in /var/lib/jenkins/*.yml
          do
            kubectl delete -f ${{antrea_yml}} --ignore-not-found=true || true
          done

          kubectl delete ns antrea-test || true

          if !(test -f TEST_FAILURE); then
            echo "=== SUCCESS !!! ==="
            exit 0
          fi
          echo "=== FAILURE !!! ==="
