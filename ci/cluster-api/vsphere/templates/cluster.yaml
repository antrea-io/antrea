apiVersion: cluster.x-k8s.io/v1beta1
kind: Cluster
metadata:
  labels:
    cluster.x-k8s.io/cluster-name: CLUSTERNAME
  name: CLUSTERNAME
  namespace: CLUSTERNAMESPACE
spec:
  clusterNetwork:
    pods:
      cidrBlocks:
      - 192.168.0.0/16
  controlPlaneRef:
    apiVersion: controlplane.cluster.x-k8s.io/v1beta1
    kind: KubeadmControlPlane
    name: CLUSTERNAME
  infrastructureRef:
    apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
    kind: VSphereCluster
    name: CLUSTERNAME
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: VSphereCluster
metadata:
  name: CLUSTERNAME
  namespace: CLUSTERNAMESPACE
spec:
  controlPlaneEndpoint:
    host: CONTROLVIP
    port: 6443
  identityRef:
    kind: Secret
    name: CLUSTERNAME
  server: VCENTERNAME
  thumbprint: THUMBPRINTVALUE
---
apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
kind: VSphereMachineTemplate
metadata:
  name: CLUSTERNAME
  namespace: CLUSTERNAMESPACE
spec:
  template:
    spec:
      cloneMode: linkedClone
      datacenter: DATACENTERNAME
      datastore: 208.1-20TB-NFS
      diskGiB: 25
      folder: CI
      memoryMiB: 8192
      network:
        devices:
        - dhcp4: true
          networkName: NETWORKNAME
      numCPUs: 4
      resourcePool: RESOURCEPOOLPATH
      server: VCENTERNAME
      storagePolicyName: ""
      template: OVATEMPLATENAME
      thumbprint: THUMBPRINTVALUE
---
apiVersion: controlplane.cluster.x-k8s.io/v1beta1
kind: KubeadmControlPlane
metadata:
  name: CLUSTERNAME
  namespace: CLUSTERNAMESPACE
spec:
  kubeadmConfigSpec:
    files:
    - content: |
        apiVersion: v1
        kind: Pod
        metadata:
          creationTimestamp: null
          name: kube-vip
          namespace: kube-system
        spec:
          containers:
          - args:
            - start
            env:
            - name: vip_arp
              value: "true"
            - name: vip_leaderelection
              value: "true"
            - name: vip_address
              value: CONTROLVIP
            - name: vip_interface
              value: eth0
            - name: vip_leaseduration
              value: "15"
            - name: vip_renewdeadline
              value: "10"
            - name: vip_retryperiod
              value: "2"
            image: ghcr.io/kube-vip/kube-vip:v0.3.5
            imagePullPolicy: IfNotPresent
            name: kube-vip
            resources: {}
            securityContext:
              capabilities:
                add:
                - NET_ADMIN
                - SYS_TIME
            volumeMounts:
            - mountPath: /etc/kubernetes/admin.conf
              name: kubeconfig
          hostNetwork: true
          volumes:
          - hostPath:
              path: /etc/kubernetes/admin.conf
              type: FileOrCreate
            name: kubeconfig
        status: {}
      owner: root:root
      path: /etc/kubernetes/manifests/kube-vip.yaml
    initConfiguration:
      nodeRegistration:
        criSocket: /var/run/containerd/containerd.sock
        name: '{{ ds.meta_data.hostname }}'
    joinConfiguration:
      nodeRegistration:
        criSocket: /var/run/containerd/containerd.sock
        name: '{{ ds.meta_data.hostname }}'
    preKubeadmCommands:
    - hostname "{{ ds.meta_data.hostname }}"
    - echo "::1         ipv6-localhost ipv6-loopback" >/etc/hosts
    - echo "127.0.0.1   localhost" >>/etc/hosts
    - echo "127.0.0.1   {{ ds.meta_data.hostname }}" >>/etc/hosts
    - echo "{{ ds.meta_data.hostname }}" >/etc/hostname
    - ip link set eth0 mtu 1442
    useExperimentalRetryJoin: true
    users:
    - name: capv
      sshAuthorizedKeys:
      - SSHAUTHORIZEDKEYS
      sudo: ALL=(ALL) NOPASSWD:ALL
  machineTemplate:
    infrastructureRef:
      apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
      kind: VSphereMachineTemplate
      name: CLUSTERNAME
  replicas: 1
  version: K8SVERSION
---
apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
kind: KubeadmConfigTemplate
metadata:
  name: CLUSTERNAME-md-0
  namespace: CLUSTERNAMESPACE
spec:
  template:
    spec:
      joinConfiguration:
        nodeRegistration:
          criSocket: /var/run/containerd/containerd.sock
          name: '{{ ds.meta_data.hostname }}'
      preKubeadmCommands:
      - hostname "{{ ds.meta_data.hostname }}"
      - echo "::1         ipv6-localhost ipv6-loopback" >/etc/hosts
      - echo "127.0.0.1   localhost" >>/etc/hosts
      - echo "127.0.0.1   {{ ds.meta_data.hostname }}" >>/etc/hosts
      - echo "{{ ds.meta_data.hostname }}" >/etc/hostname
      - ip link set eth0 mtu 1442
      users:
      - name: capv
        sshAuthorizedKeys:
        - SSHAUTHORIZEDKEYS
        sudo: ALL=(ALL) NOPASSWD:ALL
---
apiVersion: cluster.x-k8s.io/v1beta1
kind: MachineDeployment
metadata:
  labels:
    cluster.x-k8s.io/cluster-name: CLUSTERNAME
  name: CLUSTERNAME-md-0
  namespace: CLUSTERNAMESPACE
spec:
  clusterName: CLUSTERNAME
  replicas: 2
  selector:
    matchLabels: {}
  template:
    metadata:
      labels:
        cluster.x-k8s.io/cluster-name: CLUSTERNAME
    spec:
      bootstrap:
        configRef:
          apiVersion: bootstrap.cluster.x-k8s.io/v1beta1
          kind: KubeadmConfigTemplate
          name: CLUSTERNAME-md-0
      clusterName: CLUSTERNAME
      infrastructureRef:
        apiVersion: infrastructure.cluster.x-k8s.io/v1beta1
        kind: VSphereMachineTemplate
        name: CLUSTERNAME
      version: K8SVERSION
---
apiVersion: v1
kind: Secret
metadata:
  name: CLUSTERNAME
  namespace: CLUSTERNAMESPACE
stringData:
  password: CLUSTERPASSWORD
  username: CLUSTERUSERNAME
