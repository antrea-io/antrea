# Provide the active flow record timeout as a duration string. This determines
# how often the flow aggregator exports the active flow records to the flow
# collector. Thus, for flows with a continuous stream of packets, a flow record
# will be exported to the collector once the elapsed time since the last export
# event in the flow aggregator is equal to the value of this timeout.
# Valid time units are "ns", "us" (or "µs"), "ms", "s", "m", "h".
activeFlowRecordTimeout: {{ .Values.activeFlowRecordTimeout }}

# Provide the inactive flow record timeout as a duration string. This determines
# how often the flow aggregator exports the inactive flow records to the flow
# collector. A flow record is considered to be inactive if no matching record
# has been received by the flow aggregator in the specified interval.
# Valid time units are "ns", "us" (or "µs"), "ms", "s", "m", "h".
inactiveFlowRecordTimeout: {{ .Values.inactiveFlowRecordTimeout }}

# Provide the transport protocol for the flow aggregator collecting process, which is tls, tcp or udp.
aggregatorTransportProtocol: {{ .Values.aggregatorTransportProtocol | quote }}

# Provide DNS name or IP address of flow aggregator for generating TLS certificate. It must match
# the flowCollectorAddr parameter in the antrea-agent config.
flowAggregatorAddress: {{ .Values.flowAggregatorAddress | quote }}

# recordContents enables configuring some fields in the flow records. Fields can
# be excluded to reduce record size, but some features or external tooling may
# depend on these fields.
recordContents:
  # Determine whether source and destination Pod labels will be included in the flow records.
  podLabels: {{ .Values.recordContents.podLabels }}

# apiServer contains APIServer related configuration options.
apiServer:
  # The port for the flow-aggregator APIServer to serve on.
  apiPort: {{ .Values.apiServer.apiPort }}

  # Comma-separated list of Cipher Suites. If omitted, the default Go Cipher Suites will be used.
  # https://golang.org/pkg/crypto/tls/#pkg-constants
  # Note that TLS1.3 Cipher Suites cannot be added to the list. But the apiserver will always
  # prefer TLS1.3 Cipher Suites whenever possible.
  tlsCipherSuites: {{ .Values.apiServer.tlsCipherSuites | quote }}

  # TLS min version from: VersionTLS10, VersionTLS11, VersionTLS12, VersionTLS13.
  tlsMinVersion: {{ .Values.apiServer.tlsMinVersion | quote }}

# flowCollector contains external IPFIX or JSON collector related configuration options.
flowCollector:
  # Enable is the switch to enable exporting flow records to external flow collector.
  enable: {{ .Values.flowCollector.enable }}

  # Provide the flow collector address as string with format <IP>:<port>[:<proto>], where proto is tcp or udp.
  # If no L4 transport proto is given, we consider tcp as default.
  address: {{ .Values.flowCollector.address | quote }}

  # Provide the 32-bit Observation Domain ID which will uniquely identify this instance of the flow
  # aggregator to an external flow collector. If omitted, an Observation Domain ID will be generated
  # from the persistent cluster UUID generated by Antrea. Failing that (e.g. because the cluster UUID
  # is not available), a value will be randomly generated, which may vary across restarts of the flow
  # aggregator.
  {{- if .Values.flowCollector.observationDomainID }}
  observationDomainID: {{ .Values.flowCollector.observationDomainID }}
  {{- else }}
  #observationDomainID:
  {{- end }}

  # Provide format for records sent to the configured flow collector.
  # Supported formats are IPFIX and JSON.
  recordFormat: {{ .Values.flowCollector.recordFormat | quote }}

# clickHouse contains ClickHouse related configuration options.
clickHouse:
  # Enable is the switch to enable exporting flow records to ClickHouse.
  enable: {{ .Values.clickHouse.enable }}

  # Database is the name of database where Antrea "flows" table is created.
  database: "default"

  # DatabaseURL is the url to the database. TCP protocol is required.
  databaseURL: {{ .Values.clickHouse.databaseURL | quote }}

  # Debug enables debug logs from ClickHouse sql driver.
  debug: {{ .Values.clickHouse.debug }}

  # Compress enables lz4 compression when committing flow records.
  compress: {{ .Values.clickHouse.compress }}

  # CommitInterval is the periodical interval between batch commit of flow records to DB.
  # Valid time units are "ns", "us" (or "µs"), "ms", "s", "m", "h".
  # The minimum interval is 1s based on ClickHouse documentation for best performance.
  commitInterval: {{ .Values.clickHouse.commitInterval | quote }}

# s3Uploader contains configuration options for uploading flow records to AWS S3.
s3Uploader:
  # Enable is the switch to enable exporting flow records to AWS S3.
  # At the moment, the flow aggregator will look for the "standard" environment variables to
  # authenticate to AWS. These can be static credentials (AWS_ACCESS_KEY_ID,
  # AWS_SECRET_ACCESS_KEY, AWS_SESSION_TOKEN) or a Web Identity Token
  # (AWS_WEB_IDENTITY_TOKEN_FILE).
  enable: {{ .Values.s3Uploader.enable }}

  # BucketName is the name of the S3 bucket to which flow records will be uploaded. If this
  # field is empty, initialization will fail.
  bucketName: {{ .Values.s3Uploader.bucketName | quote }}

  # BucketPrefix is the prefix ("folder") under which flow records will be uploaded. If this
  # is omitted, flow records will be uploaded to the root of the bucket.
  bucketPrefix: {{ .Values.s3Uploader.bucketPrefix | quote }}

  # Region is used as a "hint" to get the region in which the provided bucket is located.
  # An error will occur if the bucket does not exist in the AWS partition the region hint
  # belongs to. If region is omitted, the value of the AWS_REGION environment variable will
  # be used, and if it is missing, we will default to "us-west-2".
  region: {{ .Values.s3Uploader.region | quote }}

  # RecordFormat defines the format of the flow records uploaded to S3. Only "CSV" is
  # supported at the moment.
  recordFormat: {{ .Values.s3Uploader.recordFormat | quote }}

  # Compress enables gzip compression when uploading files to S3. Defaults to true.
  compress: {{ .Values.s3Uploader.compress }}

  # MaxRecordsPerFile is the maximum number of records per file uploaded. It is not recommended
  # to change this value.
  maxRecordsPerFile: {{ .Values.s3Uploader.maxRecordsPerFile }}

  # UploadInterval is the duration between each file upload to S3.
  uploadInterval: {{ .Values.s3Uploader.uploadInterval | quote }}
